---
permalink: /
excerpt: "Yuhang Li"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## About

I am a third-year Ph.D. candidate in the Electrical Engineering Department at Yale University. I am a member of [Intelligent Computing Lab](https://intelligentcomputinglab.yale.edu), advised by Prof. [Priya Panda](https://scholar.google.com/citations?user=qA5WsYUAAAAJ). 
My research interests include efficient deep learning models and systems and biology-inspired artificial intelligence. 
I have focused on neural network quantization for efficient inference, neuromorphic AI with spiking neural networks, and bio-plausible optimization methods. My research is applied to the lastest topics like Diffusion Models and Large Language Models. 

Prior to Yale, I graduated from UESTC in 2020. I did research assistant/internship at the National University of Singapore, SenseTime, and Amazon. I received the 2023 Baidu PhD Fellowship. 


## News

### 2024

- Apr:  I had a talk in CoCoSyS.
- Mar:  I passed my area exam and advanced to candidacy. 
- Feb:  A paper about ANN-SNN conversion has been accepted by IJCV. 
- Jan:  I received the 2023 Baidu PhD Fellowship (10 winners/year). 

### 2023

- Sep:  A paper about SNN with dynamic timesteps is accepted to NeurIPS 2023 and a paper about Post-Training Quantization in LLM is accepted to EMNLP 2023. 
- Aug:  I will serve as the Area Chair for EMNLP 2023. 
- May:  A paper about SNN with surrogate module learning is accepted to ICML 2024. 

## Selected Publications

1. <img src="../images/ijcv24.pdf" alt="Thumbnail" width="100" align="left" style="margin-right: 10px;">
   **Error-Aware Conversion from ANN to SNN via Post-training Parameter Calibration**  
   Authors: **Yuhang Li**, Shikuang Deng, Xin Dong, Shi Gu 
   *International Journal of Computer Vision (2024): 1-24.*  
   [Paper Link](https://link.springer.com/article/10.1007/s11263-024-02046-2)  
   <br clear="left"/>

2. <img src="../images/emnlp23.pdf" alt="Thumbnail" width="100" align="left" style="margin-right: 10px;">
   **Outlier Suppression+: Accurate Quantization of Large Language Models by Equivalent and Optimal Shifting and Scaling**  
   Authors: Xiuying Wei, Yunchen Zhang, **Yuhang Li**, Xiangguo Zhang, Ruihao Gong, Jinyang Guo, Xianglong Liu
   *Conference on Empirical Methods in Natural Language Processing (2023).*  
   [Paper Link](https://arxiv.org/pdf/2304.09145)  
   <br clear="left"/>

3. <img src="../images/nips23.pdf" alt="Thumbnail" width="100" align="left" style="margin-right: 10px;">
   **SEENN: Towards Temporal Spiking Early-Exit Neural Networks**  
   Authors: **Yuhang Li**, Tamar Geller, Youngeun Kim, Priyadarshini Panda
   *Conference on Neural Information Processing System (2023).*  
   [Paper Link](https://proceedings.neurips.cc/paper_files/paper/2023/file/c801e68207da477bbc44182b9fac1129-Paper-Conference.pdf)  
   <br clear="left"/>

4. <img src="../images/icml23.pdf" alt="Thumbnail" width="100" align="left" style="margin-right: 10px;">
   **Surrogate Module Learning: Reduce the Gradient Error Accumulation in Training Spiking Neural Networks**  
   Authors: Shikuang Deng, Hao Lin, **Yuhang Li**, Shi Gu
   *International Conference on Machine Learning (2023).*  
   [Paper Link](https://proceedings.mlr.press/v202/deng23d/deng23d.pdf)  
   <br clear="left"/>

